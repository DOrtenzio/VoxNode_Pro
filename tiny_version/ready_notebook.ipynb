{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"-------------------------------------------------------\"\n",
        "echo \"üßä VoxNode ULTRA-TINY: Specialized Deployment\"\n",
        "echo \"-------------------------------------------------------\"\n",
        "\n",
        "# Installazione dipendenze ottimizzate\n",
        "pip install -q torch transformers accelerate bitsandbytes optimum\n",
        "pip install -q openai-whisper soundfile langchain langchain-community langchain-text-splitters faiss-gpu-cu12 sentence-transformers gradio\n",
        "pip install -q https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl\n",
        "\n",
        "# Forza l'installazione di flash-attn (pu√≤ richiedere tempo su T4)\n",
        "pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "# Crea la struttura delle cartelle se non l'hai gi√† fatta via file\n",
        "mkdir -p tiny_src\n",
        "touch tiny_src/__init__.py"
      ],
      "metadata": {
        "id": "KiRhts9JSPL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Ottimizzazione memoria CUDA\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Esegui l'applicazione\n",
        "%run app-tiny.py"
      ],
      "metadata": {
        "id": "GspOJWyLTJBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}