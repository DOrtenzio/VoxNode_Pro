# Reader AI - Alpha (VoxNode Branch)

![Reader AI Banner](https://img.shields.io/badge/VoiceReader-AI-blue)
![VoxNode Branch](https://img.shields.io/badge/branch-VoxNode-purple)
![Alpha Version](https://img.shields.io/badge/version-0.1.0--alpha-red)
![License](https://img.shields.io/badge/license-MIT-green)

## ðŸ“– Overview

**VoiceReader AI** is an experimental alpha-stage reading assistant that transforms spoken language into actionable insights. Built as a specialized web branch of the **VoxNode** ecosystem, this application provides a lightweight, browser-based interface for converting technical documentation, manuals, and study materials into searchable, analyzable text with AI-powered assistance.

### ðŸŽ¯ Project Context
This application extends the **VoxNode Pro** framework (an advanced Voice AI Agent for prototyping intelligent voice assistants) by providing a **web-first, browser-based solution** specifically designed for reading and analyzing technical documentation. While VoxNode Pro focuses on real-time voice interaction and complex agent systems, VoiceReader AI specializes in **document analysis through speech**.

## âœ¨ Key Differentiators from VoxNode Pro

| Feature | VoxNode Pro | VoiceReader AI |
|---------|------------|---------------|
| **Deployment** | Python/GPU server | Browser-based (no install) |
| **Target Use** | Voice agents, PBX systems | Technical documentation analysis |
| **AI Models** | Local LLMs (Phi-3, Llama-3.1) | Browser transformers + Cloud APIs |
| **Architecture** | Server-client | Pure client-side (PWA-ready) |
| **Focus** | Real-time conversation | Reading comprehension & analysis |
| **Complexity** | High (RAG, function calling) | Medium (focused on document help) |

## ðŸš€ Quick Start

### Prerequisites
- Modern web browser (Chrome/Edge recommended for best Web Speech API support)
- Microphone access
- For local AI: ~100MB-4GB storage space for model downloads

### Installation

#### Option 1: Direct Browser Usage
```bash
# Clone the repository
git clone https://github.com/your-org/voicereader-ai.git
cd voicereader-ai

# Open in browser (no server required!)
# Simply open index.html in Chrome/Edge
```

#### Option 2: Web Server (Optional)
```bash
# For better microphone permissions, run a local server
python -m http.server 8000
# Then visit http://localhost:8000
```

### Configuration Steps
1. **Open the application** in Chrome/Edge
2. **Select AI Model** on first launch:
   - **Local Models**: Choose from 3 sizes (downloads required)
   - **Cloud APIs**: Enter API keys for Groq/OpenAI/Gemini
3. **Grant microphone permissions** when prompted
4. **Start reading** technical documentation aloud

## ðŸ—ï¸ Technical Architecture

### Technology Stack
- **Frontend**: Pure HTML5, CSS3, JavaScript (ES6+)
- **Speech Recognition**: Web Speech API (no external dependencies)
- **Local AI**: Transformers.js (Hugging Face models in browser)
- **Cloud AI**: Direct API integration (Groq, OpenAI, Gemini)
- **Storage**: LocalStorage API (no backend required)
- **UI Framework**: Bootstrap 5.3 + Custom Glassmorphism CSS
- **Icons**: Font Awesome 6

### Project Structure
```
voicereader-ai/
â”œâ”€â”€ index.html              # Single-page application
â”œâ”€â”€ style/
â”‚   â””â”€â”€ styles.css          # Modern glassmorphism design
â”œâ”€â”€ script/
â”‚   â”œâ”€â”€ app.js              # Core application logic & state
â”‚   â”œâ”€â”€ speech-manager.js   # Web Speech API wrapper with streaming
â”‚   â”œâ”€â”€ chatbot-manager.js  # AI model management (local/cloud)
â”‚   â””â”€â”€ notebook-manager.js # Local storage for document collections
â””â”€â”€ README.md               # This documentation
```

### Key Technical Implementation

#### 1. Speech Recognition System
```javascript
// Web Speech API with real-time streaming
class SpeechManager {
  static recognition = new webkitSpeechRecognition();
  static continuous = true;
  static interimResults = true;
  
  // Handles both final and interim results
  onresult = (event) => {
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      const isFinal = event.results[i].isFinal;
      
      // Real-time streaming to UI
      if (isFinal) this.onFinalText(transcript);
      else this.onInterimText(transcript);
    }
  };
}
```

#### 2. AI Integration Layers
- **Layer 1**: Browser-based transformers (Xenova/distilbart-cnn-12-6)
- **Layer 2**: Cloud APIs with streaming support
- **Layer 3**: Fallback algorithms for offline/error scenarios

#### 3. Data Flow Architecture
```
User Speech â†’ Web Speech API â†’ Real-time Streaming â†’ Text Processing
       â†“                                         â†“
 Microphone Input                         UI Updates (immediate)
       â†“                                         â†“
   Browser                                AI Analysis (on demand)
       â†“                                         â†“
  LocalStorage                          Response Generation
  (Notebooks)                          (Local/Cloud AI)
```

## ðŸ”§ Integration with VoxNode Ecosystem

### Complementary Relationship
VoiceReader AI serves as a **lightweight web companion** to VoxNode Pro:

1. **Quick Documentation Analysis**: Use VoiceReader for rapid document review
2. **Training Data Preparation**: Generate transcripts for VoxNode's RAG system
3. **Mobile/Remote Access**: Browser-based access from any device
4. **User Onboarding**: Simpler interface for initial document processing

### Potential Integration Points
1. **Shared Knowledge Base**: Export VoiceReader transcripts to VoxNode's RAG
2. **Unified API Keys**: Single configuration for both platforms
3. **Complementary Use Cases**:
   - **VoxNode**: Complex PBX configuration, real-time troubleshooting
   - **VoiceReader**: Manual/documentation study, training material creation

## ðŸ› Known Issues (Alpha Release)

### Critical Issues
1. **Speech Recognition Limitations**
   - Web Speech API accuracy varies by browser/accent
   - Technical terminology recognition inconsistent
   - No custom model training possible
   - Languages problems

2. **AI Model Constraints**
   - Local browser models limited to ~4GB download
   - Cloud API costs/rate limits not fully managed
   - Context window limited for long technical docs

3. **Browser Dependencies**
   - Requires Chrome/Edge for best performance
   - Mobile Safari has limited Web Speech API support
   - No offline transcription without local models

4. **UI/UX Problems and Fake Page To Change**
   - Problems with changing ita to eng and eng to ita
   - Problems with understanding ita when the lang is set to ita, same with eng
   - Some pages not exist where going to create them

### Performance Concerns
- **Initial Load**: Local AI models require significant download time
- **Memory Usage**: Browser memory consumption with large models
- **Real-time Processing**: May lag on lower-end devices

### UX/UI Limitations
- **Visual Feedback**: Voice visualization needs refinement
- **Error Handling**: Basic error messages for API failures
- **Mobile Experience**: Touch interactions need optimization

### Technical Debt
- **Code Organization**: Needs better modularization
- **Error Recovery**: Limited handling of network interruptions
- **Testing Coverage**: Minimal automated testing
- **Security**: API keys stored in localStorage (not encrypted)

## ðŸŽ¯ Development Roadmap

### Phase 1: Alpha Stabilization (Current)
- [x] Basic speech-to-text functionality
- [x] Multi-model AI integration
- [x] Local storage for documents
- [ ] Improve error handling and user feedback
- [ ] Add export functionality

### Phase 2: Beta Features
- [ ] Progressive Web App (PWA) capabilities
- [ ] Enhanced model management
- [ ] Better mobile responsiveness
- [ ] Advanced text editing tools

### Phase 3: VoxNode Integration
- [ ] Direct API connection to VoxNode backend
- [ ] Shared knowledge base synchronization
- [ ] Unified authentication system
- [ ] Cross-platform document sharing

## ðŸ”Œ API Configuration

### Groq API Setup (Recommended)
```javascript
// In the application UI, configure:
API Provider: Groq
Model: openai/gpt-oss-120b
API Key: [Your Groq API Key]

// Technical endpoint: https://api.groq.com/openai/v1/chat/completions
```

### Adding New AI Providers
1. Extend `ChatbotManager` class in `chatbot-manager.js`
2. Implement query method for new provider
3. Add UI selector option in `index.html`
4. Update configuration handling in `app.js`

## ðŸ§ª Testing Strategy

### Manual Testing Checklist
- [ ] Microphone permissions across browsers
- [ ] Speech recognition in various environments and languages
- [ ] AI response generation with different models
- [ ] Notebook save/load functionality
- [ ] Cross-browser compatibility

### Needed Automated Tests
- Unit tests for core managers (speech, AI, storage)
- Integration tests for API endpoints
- E2E tests for user workflows
- Performance benchmarks

## ðŸ¤ Contributing to VoiceReader AI

**âš ï¸ Important**: This is an ALPHA release within the VoxNode ecosystem.

### Development Setup
```bash
# Clone repository
git clone https://github.com/your-org/voicereader-ai.git

# No build system required
# Edit HTML/JS/CSS files directly

# Use Live Server extension in VSCode for development
# Or run: npx live-server
```

### Contribution Guidelines
1. **Branch Strategy**: `feature/description` or `fix/voxnode-integration`
2. **Code Style**: Follow existing ES6+ patterns
3. **VoxNode Alignment**: Ensure compatibility with main project
4. **Documentation**: Update both README and code comments

### Priority Contribution Areas
- Speech recognition accuracy improvements
- AI model optimization for browser
- UI/UX enhancements for technical users
- Integration with VoxNode backend
- Performance optimization

## âš ï¸ Alpha Release Disclaimer

**This is an ALPHA release within the VoxNode ecosystem:**

1. **Experimental Software**: For testing and development only
2. **Breaking Changes Expected**: API and architecture will evolve
3. **Limited Production Use**: Not for critical business applications
4. **Community Development**: Contributions essential for growth
5. **Security Review Needed**: Review code before handling sensitive data

## ðŸ“„ License

MIT License - Same as VoxNode Pro parent project

## ðŸ™ Acknowledgments

- **VoxNode Pro Team**: For the foundational architecture and inspiration
- **Hugging Face**: For Transformers.js and model hosting
- **Web Standards Community**: For Web Speech API development
- **Open-source AI Community**: For accessible AI model development

## ðŸ“ž Support & Community

- **Issues**: Report via GitHub Issues (tag with `[VoiceReader]`)
- **Discussion**: Join VoxNode community channels
- **Contributions**: Essential for alpha-stage development
- **Feedback**: Critical for shaping this VoxNode branch

---

**Project Status**: Alpha - Active Development  
**Parent Project**: VoxNode Pro  
**Last Updated**: January 2026  
**Primary Maintainer**: VoxNode Development Team  
**Target Users**: Technicians, Documentation Specialists, VoxNode Users  

*"Bringing VoxNode's intelligence to document analysis through voice"*